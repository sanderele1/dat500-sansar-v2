{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ca9282f-9ff1-495a-b5e1-88f347bf4b7c",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1d36f38-3b4e-43ac-9e57-a46290cc52bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expectes a *.fasta file\n",
    "input_file = \"hdfs:///files/salmonella/assembledASM694v2\"\n",
    "input_segment_size = 80\n",
    "\n",
    "intermediate_window_size = 1024\n",
    "shotgun_sequence_length = 75\n",
    "\n",
    "partitions = 128\n",
    "\n",
    "# Outputs a sequence file with (position, sequence)\n",
    "output_file = \"hdfs:///files/salmonella/window\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7087d47e-a2b3-43ae-a024-c157f4893ae0",
   "metadata": {},
   "source": [
    "## TODO:\n",
    "\n",
    "1. [ ] Check that groupByKey is indeed corretly ordered (just sort it, as atomic values have index)\n",
    "2. [ ] Change grouping method to use -offset, so to make it actually shift the offset right, instead of left\n",
    "3. [ ] Validate indices are correctly preserved by resizing method, even with offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a34544bd-681f-4bf3-8c94-3174cac73e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/spark/python/pyspark'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42446fd7-bb06-42e0-b8b3-6a857f5d1305",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "2022-04-24 17:00:36,149 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2022-04-24 17:00:45,682 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .master(\"yarn\")\n",
    "         .appName(\"python-testing\")\n",
    "         .config(\"spark.executor.instances\", 16)\n",
    "         .config(\"spark.executor.memory\", \"1536m\")\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b631a30-2e1d-4066-b254-6ca3575cc349",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40b8a858-52e5-4f9d-896d-bc76f77413c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://namenode:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>yarn</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>python-testing</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=yarn appName=python-testing>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6369460d-2619-4007-accb-5b93567f081b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['AGAGATTACGTCTGGTTGCAAGAGATCATGACAGGGGGAATTGGTTGAAAATAAATATATCGCCAGCAGCACATGAACAA']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = sc.textFile(input_file).filter(lambda x: not x.startswith('>'))\n",
    "raw_data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e21ea5bc-5d48-4748-93bc-edbb03c50594",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = raw_data#.sample(False, 0.05, 1)\n",
    "#data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "453e6e5e-4af6-415a-8718-9f372a4e75b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(raw, segmentLength):\n",
    "    indexed = raw.zipWithIndex().map(lambda x: (x[1], x[0]))\n",
    "    atomized = indexed.flatMap(lambda x: [(x[0] * segmentLength + i, v) for i, v in enumerate(x[1])])\n",
    "    return atomized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a829881d-6f5e-4ed1-80d2-9f046a68b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize(atomized, newSize, offset = 0):\n",
    "    keyed = atomized.map(lambda x: (((x[0] - offset) // newSize) * newSize + offset, (x[0], x[1])))\n",
    "    grouped = keyed.groupByKey()\n",
    "    ordered = grouped.mapValues(lambda x: sorted(x, key=lambda k: k[0]))\n",
    "    stringified = ordered.mapValues(lambda x: (x[0][0], \"\".join([v[1] for v in x])))\n",
    "    return stringified\n",
    "\n",
    "def slidingWindow(stringified, window_size):\n",
    "    def window(x):\n",
    "        s = x[1][1]\n",
    "        windows = []\n",
    "        for i in range(len(s) - window_size):\n",
    "            windows.append((x[0] + i, s[i:i+window_size]))\n",
    "            \n",
    "        return windows\n",
    "\n",
    "    return stringified.flatMap(window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d5a995b-e7a0-4f77-bad4-2e42e37c6cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(340, 'G'), (341, 'A'), (342, 'G'), (343, 'T'), (344, 'G')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre = preprocess(data, input_segment_size).repartition(partitions)\n",
    "pre.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d600369-da5c-4ca2-8759-98907a456720",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_offset_0 = resize(pre, intermediate_window_size, 0)\n",
    "window_0 = slidingWindow(window_offset_0, shotgun_sequence_length)\n",
    "\n",
    "window_offset_1 = resize(pre, intermediate_window_size, shotgun_sequence_length)\n",
    "window_1 = slidingWindow(window_offset_1, shotgun_sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25ae4111-0f4b-422e-ad04-4a5e7e82c2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unioned = window_0.union(window_1).repartition(partitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3a4185f-2da2-40b0-b5ad-873ddbc712f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4951308"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windowed = unioned.distinct()\n",
    "windowed.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edfb9bca-bde0-4b65-8b33-fe86f809871f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3532223,\n",
       "  'GCCACGCTATCGACGGTACCTTTTAATACCCGGTTGCTGCCAAGCGGCGTGATTTCGGCACGATATCCCGGACGC'),\n",
       " (3729573,\n",
       "  'AGCTCTTTGGTCTCTTTCGGGTTAAGGCCAGCCGCCGGTTCGTCGAGCATCAGAATTTCTGGCTGCGTCACCATG')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windowed.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7771203-aa96-4825-baa8-a6f50a488bb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "windowed.saveAsSequenceFile(output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
